{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t/tzelilai/Desktop/Thesis/venv_d4data/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch \n",
    "import gc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'd4data/bias-detection-model'\n",
    "access_token = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer with the access token\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    token=access_token,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    from_tf=True\n",
    ")\n",
    "tokenizer = transformers.DistilBertTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    token=access_token\n",
    ")\n",
    "\n",
    "# Create the pipeline with the specified model and tokenizer\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    truncation=True,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/t/tzelilai/Desktop/Thesis/output.txt','r') as f:\n",
    "  content = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_file(input_file):\n",
    " # You can change the max_length parameter to split the file differently\n",
    "    max_length = 1024\n",
    "    with open(input_file, 'r') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    chunks = [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "    \n",
    "    for index, chunk in enumerate(chunks):\n",
    "        with open(f\"{input_file.split('.txt')[0]}_{index + 1}.txt\", 'w') as file:\n",
    "            file.write(chunk)\n",
    "\n",
    "# Replace 'input.txt' with the path to your .txt file\n",
    "split_text_file('output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_1.txt', 'r') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pipeline(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'Biased', 'score': 0.9550895690917969}]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_d4data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
