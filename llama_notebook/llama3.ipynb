{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch \n",
        "import gc \n",
        "import json\n",
        "from tokens import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6a864427be804607aa7f009d616d3f97",
            "96047562598a45069fd9dc9d8f4b393a",
            "93c7fd87c8ed4769aad9a4170caf03f4",
            "e7c60755ec374ade9a830080c58ce078",
            "2627ed72f18841c981f9e0a2b8aa48ee",
            "2bedcbb8663949018cdb54e1b2894795",
            "11f297fcc4274958b5c5bda3f159e0d7",
            "56f0d8548d3a4ed9aa284d056ee3c136",
            "e6325cd030ed4100b9933be76b1876ae",
            "0c9dbc6ccede49a8b2bf17034b052c19",
            "cadff175cb4f4a47a3663628238e088b"
          ]
        },
        "id": "JaPGT7BqEDQf",
        "outputId": "9d3375a8-0df1-41a1-b0cd-cfd384552a3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/t/tzelilai/Desktop/Thesis/venv/lib64/python3.9/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "2024-11-25 17:00:38.140167: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-11-25 17:00:38.156038: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-25 17:00:38.175246: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-25 17:00:38.181087: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-25 17:00:38.195303: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-25 17:00:40.394529: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
            "Loading checkpoint shards: 100%|██████████| 4/4 [04:40<00:00, 70.07s/it]\n",
            "/home/t/tzelilai/Desktop/Thesis/venv/lib64/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:809: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the model and tokenizer with the access token\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=access_token,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    load_in_4bit=True\n",
        ")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=access_token\n",
        ")\n",
        "\n",
        "# Create the pipeline with the specified model and tokenizer\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8gzj1zr8KIxV"
      },
      "outputs": [],
      "source": [
        "def repeater(messages):\n",
        "\n",
        "  # Apply chat template to messages\n",
        "  prompt = pipeline.tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      tokenize=False,\n",
        "      add_generation_prompt=True\n",
        "  )\n",
        "\n",
        "  # Define terminators\n",
        "  terminators = [\n",
        "      pipeline.tokenizer.eos_token_id,\n",
        "  ]\n",
        "\n",
        "  # Generate text\n",
        "  outputs = pipeline(\n",
        "      prompt,\n",
        "      max_new_tokens=2024*2,\n",
        "      eos_token_id=terminators,\n",
        "      do_sample=True,\n",
        "      temperature=1,\n",
        "      top_p=0.9,\n",
        "  )\n",
        "  return len(prompt), outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5 are available.\n"
          ]
        }
      ],
      "source": [
        "with open('output2.json', 'r') as file: \n",
        "    articles = json.load(file)\n",
        "\n",
        "print(f'{len(articles[len(articles) - 1])} are available.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "content = \"\"\n",
        "for i, article in enumerate(articles[0]):\n",
        "    content += \"Article\" + str(i+1) + \":\" + article + '\\n'\n",
        "# Define messages\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an AI assistant tasked with producing NEUTRAL news article based on the provided article summaries.\"\n",
        "                                  \"Take in consideration all the provided articles and write a new article as a journalist, ensuring the content\" \n",
        "                                  \"is unbiased, factual, and informative.\"},\n",
        "                                \n",
        "    {\"role\": \"user\", \"content\": content}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "content = \"\"\n",
        "for i, article in enumerate(articles[0]):\n",
        "    content += \"Article\" + str(i+1) + \":\" + article + '\\n'\n",
        "# Define messages\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an AI assistant tasked with producing a NEUTRAL and UNBIASED news article based on the provided article summaries. \"\n",
        "                                  \"Your goal is to analyze all the provided information and write a single cohesive news article as a professional journalist. \"\n",
        "                                  \"The content must be factual, concise, and informative. Do not include personal opinions or assumptions. \"\n",
        "                                  \"Ensure the tone is formal and journalistic, suitable for a wide audience. \"\n",
        "                                  \"Provide a clear and appropriate title for the article.\"},\n",
        "                                \n",
        "    {\"role\": \"user\", \"content\": content}\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "prompt_len, outputs = repeater(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Unpacking the Uncertainties Surrounding the Proposed Department of Government Efficiency\n",
            "\n",
            "In recent weeks, the appointment of tech mogul Elon Musk and Vivek Ramaswamy to lead the Department of Government Efficiency (DOGE) has sparked a mix of curiosity and concern. While the idea of harnessing the expertise of private sector innovators to optimize government operations seems appealing, the nuances of Musk's involvement have raised questions about potential conflicts of interest and the feasibility of the initiative.\n",
            "\n",
            "Proponents of the DOGE, like Ark Invest CEO Cathie Wood, argue that Musk's companies, including SpaceX and Tesla, possess valuable insights that can inform more efficient government spending. Wood, a longtime supporter of Musk and his companies, believes his track record of overcoming challenges in business can bring a fresh perspective to government efficiency initiatives. Musk himself aims to cut $2 trillion from the federal budget, although the feasibility and implementation of this initiative are uncertain.\n",
            "\n",
            "Critics, however, are skeptical about the arrangement, citing potential conflicts of interest and concerns that Musk's involvement may prioritize his own interests over the broader public good. The appointment has raised eyebrows due to Musk's significant stakes in industries that could be impacted by his recommendations, including space exploration, renewable energy, and transportation.\n",
            "\n",
            "Moreover, the Department of Government Efficiency's structure and objectives remain unclear, leaving many questions unanswered. Will Musk and Ramaswamy be tasked with making policy decisions, or will they provide guidance and advice? How will they navigate the complex web of regulations and potential conflicts of interest?\n",
            "\n",
            "The appointment of the DOGE has also sparked concerns about Musk's ability to objectively advise on government reform, given his dominant position in social media and his close relationship with President-elect Donald Trump. While Musk's understanding of the technological landscape and control over vast amounts of proprietary data could bring valuable insights, his involvement raises concerns about the integrity of the process.\n",
            "\n",
            "In conclusion, the proposed Department of Government Efficiency remains a work in progress, with many uncertainties surrounding its objectives, structure, and potential impact. While the idea of harnessing private sector expertise to optimize government operations is intriguing, the nuances of Musk's involvement and the department's operations will require closer scrutiny to ensure transparency and accountability.."
          ]
        }
      ],
      "source": [
        "print(outputs[0][\"generated_text\"][prompt_len:], end='.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('generated_article.json', 'w') as file: \n",
        "    json.dump([outputs[0][\"generated_text\"][prompt_len:]], file, indent=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "del outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "del model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c9dbc6ccede49a8b2bf17034b052c19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f297fcc4274958b5c5bda3f159e0d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2627ed72f18841c981f9e0a2b8aa48ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bedcbb8663949018cdb54e1b2894795": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56f0d8548d3a4ed9aa284d056ee3c136": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a864427be804607aa7f009d616d3f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96047562598a45069fd9dc9d8f4b393a",
              "IPY_MODEL_93c7fd87c8ed4769aad9a4170caf03f4",
              "IPY_MODEL_e7c60755ec374ade9a830080c58ce078"
            ],
            "layout": "IPY_MODEL_2627ed72f18841c981f9e0a2b8aa48ee"
          }
        },
        "93c7fd87c8ed4769aad9a4170caf03f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56f0d8548d3a4ed9aa284d056ee3c136",
            "max": 654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6325cd030ed4100b9933be76b1876ae",
            "value": 654
          }
        },
        "96047562598a45069fd9dc9d8f4b393a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bedcbb8663949018cdb54e1b2894795",
            "placeholder": "​",
            "style": "IPY_MODEL_11f297fcc4274958b5c5bda3f159e0d7",
            "value": "config.json: 100%"
          }
        },
        "cadff175cb4f4a47a3663628238e088b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6325cd030ed4100b9933be76b1876ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7c60755ec374ade9a830080c58ce078": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c9dbc6ccede49a8b2bf17034b052c19",
            "placeholder": "​",
            "style": "IPY_MODEL_cadff175cb4f4a47a3663628238e088b",
            "value": " 654/654 [00:00&lt;00:00, 42.4kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
