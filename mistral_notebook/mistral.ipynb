{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t/tzelilai/Desktop/Thesis/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch \n",
    "import gc \n",
    "import json \n",
    "from tokens import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t/tzelilai/Desktop/Thesis/venv/lib64/python3.9/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:14<00:00, 24.95s/it]\n",
      "/home/t/tzelilai/Desktop/Thesis/venv/lib64/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:796: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "2024-11-16 16:35:57.959161: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-16 16:35:57.972897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-16 16:35:57.989383: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-16 16:35:57.994287: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-16 16:35:58.005754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-16 16:36:22.654356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer with the access token\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=access_token,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    load_in_4bit=True\n",
    ")\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=access_token\n",
    ")\n",
    "\n",
    "# Create the pipeline with the specified model and tokenizer\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeater(messages):\n",
    "\n",
    "    # Apply chat template to messages\n",
    "    prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    # Define terminators\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "    ]\n",
    "\n",
    "    # Generate text\n",
    "    outputs = pipeline(\n",
    "        prompt,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.5,\n",
    "        top_p=0.9,\n",
    "        max_new_tokens=2024*2\n",
    "    )\n",
    "    return len(prompt), outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 are available.\n"
     ]
    }
   ],
   "source": [
    "with open('articles.json', 'r') as file: \n",
    "    articles = json.load(file)\n",
    "\n",
    "print(f'{len(articles[len(articles) - 1])} are available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant tasked with producing NEUTRAL news article based on the provided article information.\"\n",
    "                                  \"Try to filter the bias that maybe existent in the article\" \n",
    "                                  \"Write a new article as a journalist, ensuring the content is unbiased, factual, and informative.\"},\n",
    "                                \n",
    "    {\"role\": \"user\", \"content\": articles[0][0]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "source": [
    "prompt_len, outputs = repeater(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Title: Keir Starmer Revises Ministerial Gift and Hospitality Rules in Response to Public Scrutiny\n",
      "\n",
      "Keir Starmer, the Prime Minister, has amended the rules governing gifts and hospitality received by ministers, following a series of criticisms over freebies accepted by senior Labour figures. The updated ministerial code emphasizes the importance of maintaining public trust in the propriety of ministers' actions.\n",
      "\n",
      "Under the revised code, ministers are expected to consider the need to uphold public confidence when deciding whether to accept gifts or hospitality. A monthly register of gifts received by ministers, valued at over £140, will be published, as opposed to the previous quarterly schedule.\n",
      "\n",
      "The changes come after a backlash over gifts received by Starmer, including tickets to see Taylor Swift, and clothing from Labour peer and donor Lord Alli. In response, Starmer, Deputy Prime Minister Angela Rayner, and Chancellor Rachel Reeves have ceased accepting donated clothing.\n",
      "\n",
      "The updated code states that ministers should not accept gifts, hospitality, or services that might reasonably appear to compromise their judgement or create an inappropriate obligation. This principle extends to family members as well. However, the code acknowledges that ministers may need to attend events where hospitality is offered due to their duties.\n",
      "\n",
      "The decision to accept or decline gifts remains a matter of personal judgement for ministers. The monthly register will include details and the value of gifts and hospitality received and given by ministers in their ministerial capacity.\n",
      "\n",
      "The revisions also see the publication of the list of ministers' interests more frequently, moving from twice a year to quarterly. This list includes any private interests that could potentially conflict with a minister's public duties.\n",
      "\n",
      "Notably, the Prime Minister is among those renting out their family home, following the tradition set by previous prime ministers such as David Cameron and Theresa May. This list provides transparency regarding any private interests that could potentially conflict with a minister's public duties.."
     ]
    }
   ],
   "source": [
    "print(outputs[0][\"generated_text\"][prompt_len:], end='.')\n",
    "\n",
    "with open('mistral.txt', 'w') as file: \n",
    "    file.write(outputs[0][\"generated_text\"][prompt_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del outputs\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
